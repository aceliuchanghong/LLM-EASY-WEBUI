### LLM-EASY-WEBUI

mainly for llama3

### 来一个测试环境

```shell
pip freeze > requirements.txt
conda create -n myLLM_WEBUI python=3.11
conda activate myLLM_WEBUI
pip install -r requirements.txt --proxy=127.0.0.1:10809
```

### *Star History*

![Star History Chart](https://api.star-history.com/svg?repos=aceliuchanghong/LLM-EASY-WEBUI&type=Date)
