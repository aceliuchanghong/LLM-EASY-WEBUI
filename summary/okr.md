A.假设录屏上传获取文档

B.考虑自己跑模型出结果

考虑2种方案成本,大概5.1 22:00之前给出

假设录屏上传获取文档:
非我之事,之后再说

考虑自己跑模型出结果情况

1. 视频整体总结(大概是150-250个字符之间)

- 5.4 22:00之前给出脚本,本地的demo测试通过+github代码提供+操作手册

2. 章节Chapter摘要(时间点+摘要一句话+该时间段摘要内容)

- 5.5 22:00前给出脚本,本地的demo测试通过+github代码提供+操作手册

3. 问答小助手(争取)

- 上面2个解决之后再考虑

### A方案成本计算
```text
假设需要录屏的视频大概n个,视频长度平均设为x分钟,每个都2倍速播放进行录制需要x/2分钟
最多同时2个同时进行,然后每一个获取文本大概需要5分钟,实际消耗时间公式为:
```
`t = nx/4 + 5n`
```text
假设100个视频,20分钟,那么就是需要:1000分钟==>16.7小时
好处就是简单,显而易见,可以准确知道进度,但是之后再有这个任务就又需要这样做
```

### B方案成本计算
技术选型
```text
价格:https://openai.com/pricing

首先openai的音频大小限制为25MB,考虑到正常录音都不大,这儿暂且不考虑,

我建议这儿采用hf模型:Systran/faster-whisper-large-v3 (针对文本识别)

对于大模型,我本意是使用llama3,但是考虑的各个产品模型一致性,我这儿还是采用:
gpt-4-turbo
```
```
此处仅考虑输入的值,输出的较少暂不考虑
假设一般人正常说话的速度应该在250字每分钟左右,1个汉字大致是2~2.5个token,设为2.1
那么视频数目n,长度x,token数目为:
```
`num = n * x * 2.1 * 250`

![img_3.png](..%2Fusing_files%2Fimg%2Fimg_3.png)

```text
假设100个视频,20分钟,那么token数目为:1,050,000 ==>10美元-12美元左右
(若llama3,仅需1块钱-2块钱)
人工费至少8个工时
好处是如果做好了,之后可能就会方便复用,坏处就是不一定效果很好
```



工时记录
```text
4.30 2h ==>程序框架设计,模型下载
5.1 2h ==>程序编写,模型下载,技术选型,成本估算
5.2 3h ==>测试模型,编写代码
```
